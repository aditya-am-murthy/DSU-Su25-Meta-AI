 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Exploration\n",
    "\n",
    "Welcome to the Video Similarity Learning project! In this notebook, we'll explore the dataset and understand the structure of video data.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Understand the structure of video data\n",
    "- Load and visualize video frames\n",
    "- Explore the dataset metadata\n",
    "- Understand the similarity learning problem\n",
    "- **Complete 5 hands-on exercises** that require critical thinking\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Make sure you have:\n",
    "1. Run the data download script: `python scripts/download_data.py`\n",
    "2. Installed all required packages: `pip install -r requirements.txt`\n",
    "\n",
    "## Important Note\n",
    "\n",
    "This notebook contains **interactive exercises** throughout. Each exercise builds on the previous concepts and requires you to think critically about the data and write code from scratch. Simply copying from ChatGPT won't help you understand the underlying concepts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import our utilities\n",
    "from utils.video_utils import load_video, get_video_info, visualize_frames\n",
    "from utils.data_utils import VideoDataset, create_sample_dataset\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "Let's start by exploring the structure of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_dir = project_root / \"data\" / \"videos\"\n",
    "metadata_file = data_dir / \"sample_metadata.csv\"\n",
    "pairs_file = data_dir / \"similarity_pairs.csv\"\n",
    "\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Metadata file: {metadata_file}\")\n",
    "print(f\"Pairs file: {pairs_file}\")\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"\\nData directory exists: {data_dir.exists()}\")\n",
    "print(f\"Metadata file exists: {metadata_file.exists()}\")\n",
    "print(f\"Pairs file exists: {pairs_file.exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "if metadata_file.exists():\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    print(\"Dataset Metadata:\")\n",
    "    print(f\"Number of videos: {len(metadata)}\")\n",
    "    print(f\"Columns: {list(metadata.columns)}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    display(metadata.head())\n",
    "    \n",
    "    print(\"\\nDataset statistics:\")\n",
    "    display(metadata.describe())\n",
    "else:\n",
    "    print(\"Metadata file not found. Please run the data download script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 1: Data Quality Check\n",
    "\n",
    "**Task**: Write code to identify potential data quality issues in the metadata.\n",
    "\n",
    "**Requirements**:\n",
    "1. Check for missing values in each column\n",
    "2. Identify any duplicate video filenames\n",
    "3. Check if all video files mentioned in metadata actually exist\n",
    "4. Find any videos with unusual properties (very short/long duration, extreme file sizes)\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your data quality check code\n",
    "# Hint: Use pandas functions like isnull(), duplicated(), and file existence checks\n",
    "\n",
    "# 1. Check for missing values\n",
    "# Your code here...\n",
    "\n",
    "# 2. Check for duplicate filenames\n",
    "# Your code here...\n",
    "\n",
    "# 3. Check if video files exist\n",
    "# Your code here...\n",
    "\n",
    "# 4. Find unusual videos\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Video Data Exploration\n",
    "\n",
    "Now let's explore the actual video files and understand their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List video files\n",
    "video_files = list(data_dir.glob(\"*.mp4\"))\n",
    "print(f\"Found {len(video_files)} video files\")\n",
    "\n",
    "if video_files:\n",
    "    print(\"\\nFirst 5 video files:\")\n",
    "    for video_file in video_files[:5]:\n",
    "        print(f\"  - {video_file.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze video properties\n",
    "video_info_list = []\n",
    "\n",
    "for video_file in tqdm(video_files[:10], desc=\"Analyzing videos\"):  # Analyze first 10 videos\n",
    "    try:\n",
    "        info = get_video_info(str(video_file))\n",
    "        info['filename'] = video_file.name\n",
    "        video_info_list.append(info)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing {video_file.name}: {e}\")\n",
    "\n",
    "if video_info_list:\n",
    "    video_info_df = pd.DataFrame(video_info_list)\n",
    "    print(\"\\nVideo properties:\")\n",
    "    display(video_info_df.describe())\n",
    "    \n",
    "    # Plot video durations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(video_info_df['duration'], bins=20, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Duration (seconds)')\n",
    "    plt.ylabel('Number of videos')\n",
    "    plt.title('Distribution of Video Durations')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 2: Video Property Analysis\n",
    "\n",
    "**Task**: Analyze the relationship between video properties and create insightful visualizations.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a scatter plot showing the relationship between video duration and file size\n",
    "2. Group videos by label and create box plots showing duration distribution for each label\n",
    "3. Calculate the correlation coefficient between duration and file size\n",
    "4. Identify the video with the highest and lowest frame rate\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your video property analysis code\n",
    "\n",
    "# 1. Scatter plot: duration vs file size\n",
    "# Your code here...\n",
    "\n",
    "# 2. Box plots by label\n",
    "# Your code here...\n",
    "\n",
    "# 3. Correlation coefficient\n",
    "# Your code here...\n",
    "\n",
    "# 4. Frame rate analysis\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Video Frame Visualization\n",
    "\n",
    "Let's load and visualize frames from some videos to understand their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize a sample video\n",
    "if video_files:\n",
    "    sample_video = str(video_files[0])\n",
    "    print(f\"Loading video: {os.path.basename(sample_video)}\")\n",
    "    \n",
    "    # Load video frames\n",
    "    frames = load_video(sample_video, max_frames=30)\n",
    "    print(f\"Loaded {len(frames)} frames with shape: {frames.shape}\")\n",
    "    \n",
    "    # Visualize frames\n",
    "    visualize_frames(frames, num_frames=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 3: Frame Analysis\n",
    "\n",
    "**Task**: Analyze the visual content of video frames and identify patterns.\n",
    "\n",
    "**Requirements**:\n",
    "1. Load frames from 3 different videos (different labels)\n",
    "2. Calculate the average brightness of each frame\n",
    "3. Create a plot showing brightness variation over time for each video\n",
    "4. Identify which video has the most consistent brightness\n",
    "5. Calculate the standard deviation of brightness for each video\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your frame analysis code\n",
    "\n",
    "# 1. Load frames from 3 different videos\n",
    "# Your code here...\n",
    "\n",
    "# 2. Calculate average brightness for each frame\n",
    "# Your code here...\n",
    "\n",
    "# 3. Plot brightness over time\n",
    "# Your code here...\n",
    "\n",
    "# 4. Identify most consistent video\n",
    "# Your code here...\n",
    "\n",
    "# 5. Calculate brightness standard deviation\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Similarity Pairs Analysis\n",
    "\n",
    "Let's explore the similarity pairs to understand how the similarity learning problem is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load similarity pairs\n",
    "if pairs_file.exists():\n",
    "    pairs = pd.read_csv(pairs_file)\n",
    "    print(\"Similarity Pairs:\")\n",
    "    print(f\"Number of pairs: {len(pairs)}\")\n",
    "    print(f\"Columns: {list(pairs.columns)}\")\n",
    "    print(\"\\nFirst few pairs:\")\n",
    "    display(pairs.head())\n",
    "    \n",
    "    # Analyze similarity distribution\n",
    "    print(\"\\nSimilarity distribution:\")\n",
    "    similarity_counts = pairs['similarity'].value_counts()\n",
    "    print(similarity_counts)\n",
    "    \n",
    "    # Plot similarity distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    similarity_counts.plot(kind='bar', color=['red', 'green'])\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.ylabel('Number of pairs')\n",
    "    plt.title('Distribution of Similarity Pairs')\n",
    "    plt.xticks([0, 1], ['Different (0)', 'Similar (1)'])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Pairs file not found. Please run the data download script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 4: Similarity Pair Investigation\n",
    "\n",
    "**Task**: Deep dive into the similarity pairs to understand the dataset structure.\n",
    "\n",
    "**Requirements**:\n",
    "1. Find the most common video pairs (which videos appear together most often)\n",
    "2. Create a histogram showing how many times each video appears in pairs\n",
    "3. Check if there are any videos that only appear in similar pairs or only in different pairs\n",
    "4. Calculate the percentage of similar vs different pairs for each label combination\n",
    "5. Identify any potential bias in the dataset\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your similarity pair investigation code\n",
    "\n",
    "# 1. Find most common video pairs\n",
    "# Your code here...\n",
    "\n",
    "# 2. Histogram of video appearances\n",
    "# Your code here...\n",
    "\n",
    "# 3. Check for videos with only one type of pair\n",
    "# Your code here...\n",
    "\n",
    "# 4. Similarity percentage by label combination\n",
    "# Your code here...\n",
    "\n",
    "# 5. Identify dataset bias\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Label Distribution Analysis\n",
    "\n",
    "Let's analyze the distribution of labels in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze label distribution\n",
    "if metadata_file.exists():\n",
    "    label_counts = metadata['label'].value_counts().sort_index()\n",
    "    \n",
    "    print(\"Label distribution:\")\n",
    "    print(label_counts)\n",
    "    \n",
    "    # Plot label distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    label_counts.plot(kind='bar')\n",
    "    plt.xlabel('Label')\n",
    "    plt.ylabel('Number of videos')\n",
    "    plt.title('Distribution of Video Labels')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(label_counts.values, labels=label_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Label Distribution (Pie Chart)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 5: Advanced Label Analysis\n",
    "\n",
    "**Task**: Perform advanced analysis of label patterns and relationships.\n",
    "\n",
    "**Requirements**:\n",
    "1. Create a heatmap showing the similarity matrix between different labels\n",
    "2. Calculate the average video duration for each label\n",
    "3. Find the label with the highest variance in video duration\n",
    "4. Create a visualization showing the relationship between label and video properties\n",
    "5. Suggest potential improvements to the dataset based on your analysis\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your advanced label analysis code\n",
    "\n",
    "# 1. Create similarity matrix heatmap\n",
    "# Your code here...\n",
    "\n",
    "# 2. Average duration by label\n",
    "# Your code here...\n",
    "\n",
    "# 3. Duration variance by label\n",
    "# Your code here...\n",
    "\n",
    "# 4. Label vs properties visualization\n",
    "# Your code here...\n",
    "\n",
    "# 5. Dataset improvement suggestions\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Statistics Summary\n",
    "\n",
    "Let's create a comprehensive summary of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset summary\n",
    "print(\"=== DATASET SUMMARY ===\")\n",
    "print(f\"Total videos: {len(metadata) if metadata_file.exists() else 'N/A'}\")\n",
    "print(f\"Total similarity pairs: {len(pairs) if pairs_file.exists() else 'N/A'}\")\n",
    "print(f\"Number of unique labels: {metadata['label'].nunique() if metadata_file.exists() else 'N/A'}\")\n",
    "\n",
    "if video_info_list:\n",
    "    avg_duration = np.mean([info['duration'] for info in video_info_list])\n",
    "    avg_fps = np.mean([info['fps'] for info in video_info_list])\n",
    "    avg_resolution = f\"{int(np.mean([info['width'] for info in video_info_list]))}x{int(np.mean([info['height'] for info in video_info_list]))}\"\n",
    "    \n",
    "    print(f\"Average video duration: {avg_duration:.2f} seconds\")\n",
    "    print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "    print(f\"Average resolution: {avg_resolution}\")\n",
    "\n",
    "print(\"\\n=== DATASET STRUCTURE ===\")\n",
    "print(\"data/\")\n",
    "print(\"â”œâ”€â”€ videos/\")\n",
    "print(\"â”‚   â”œâ”€â”€ sample_video_0000.mp4\")\n",
    "print(\"â”‚   â”œâ”€â”€ sample_video_0001.mp4\")\n",
    "print(\"â”‚   â”œâ”€â”€ ...\")\n",
    "print(\"â”‚   â”œâ”€â”€ sample_metadata.csv\")\n",
    "print(\"â”‚   â””â”€â”€ similarity_pairs.csv\")\n",
    "print(\"â””â”€â”€ models/\")\n",
    "print(\"    â””â”€â”€ (pre-trained model placeholders)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ FINAL EXERCISE: Dataset Insights Report\n",
    "\n",
    "**Task**: Write a comprehensive analysis report based on your findings.\n",
    "\n",
    "**Requirements**:\n",
    "1. Summarize the key characteristics of the dataset\n",
    "2. Identify potential challenges for video similarity learning\n",
    "3. Suggest preprocessing steps that might be helpful\n",
    "4. Propose a strategy for handling class imbalance (if any)\n",
    "5. List 3 potential model architectures that might work well for this data\n",
    "\n",
    "**Your report here** (write in markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your dataset insights report\n",
    "report = \"\"\"\n",
    "## Dataset Insights Report\n",
    "\n",
    "### Key Characteristics:\n",
    "[Your analysis here]\n",
    "\n",
    "### Potential Challenges:\n",
    "[Your analysis here]\n",
    "\n",
    "### Suggested Preprocessing:\n",
    "[Your suggestions here]\n",
    "\n",
    "### Class Imbalance Strategy:\n",
    "[Your strategy here]\n",
    "\n",
    "### Recommended Model Architectures:\n",
    "[Your recommendations here]\n",
    "\"\"\"\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've explored:\n",
    "\n",
    "âœ… **Dataset Structure**: Understanding how videos and metadata are organized\n",
    "âœ… **Video Properties**: Analyzing duration, resolution, and frame rates\n",
    "âœ… **Frame Visualization**: Seeing what the actual video content looks like\n",
    "âœ… **Similarity Pairs**: Understanding how similarity learning is structured\n",
    "âœ… **Label Distribution**: Analyzing the distribution of video categories\n",
    "âœ… **5 Interactive Exercises**: Hands-on analysis requiring critical thinking\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Video Similarity Learning** is about determining whether two videos are similar or different\n",
    "2. **Frame Extraction** is crucial - we extract multiple frames from each video to capture temporal information\n",
    "3. **Data Organization** matters - we need both individual videos and similarity pairs for training\n",
    "4. **Visual Patterns** - our synthetic dataset has different visual patterns that should be learnable\n",
    "5. **Critical Analysis** - understanding data quality and patterns is essential for model success\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "In the next notebook, we'll learn about **Feature Extraction** - how to convert video frames into numerical features that our models can use.\n",
    "\n",
    "---\n",
    "\n",
    "**Questions to think about:**\n",
    "- What makes two videos similar in our dataset?\n",
    "- How might we improve the dataset for better learning?\n",
    "- What challenges do you see in video similarity detection?\n",
    "- How would you handle videos of different lengths?\n",
    "- What preprocessing steps would be most important for this task?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}