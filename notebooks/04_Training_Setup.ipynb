 {
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 - Training Setup\n",
    "\n",
    "In this notebook, we'll set up the training pipeline for video similarity learning.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- Prepare data loaders for training\n",
    "- Configure training parameters and optimizers\n",
    "- Set up data augmentation strategies\n",
    "- Implement training loops and validation\n",
    "- **Complete 4 hands-on exercises** for training setup\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "**Data Loaders**: Efficiently load and batch data during training.\n",
    "\n",
    "**Optimizers**: Algorithms that update model parameters to minimize loss.\n",
    "\n",
    "**Data Augmentation**: Techniques to increase dataset diversity.\n",
    "\n",
    "**Training Loop**: The iterative process of forward pass, loss calculation, and backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the project root to the path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "\n",
    "# Import our utilities\n",
    "from utils.data_utils import VideoDataset, create_sample_dataset\n",
    "from utils.model_utils import VideoSiameseNetwork, VideoTripletNetwork\n",
    "from utils.training_utils import ContrastiveLoss, TripletLoss\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Let's prepare our data for training by creating data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = project_root / \"configs\" / \"default_config.yaml\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_dir = project_root / \"data\" / \"videos\"\n",
    "metadata_file = data_dir / \"sample_metadata.csv\"\n",
    "pairs_file = data_dir / \"similarity_pairs.csv\"\n",
    "\n",
    "# Load metadata and pairs\n",
    "metadata = pd.read_csv(metadata_file)\n",
    "pairs = pd.read_csv(pairs_file)\n",
    "\n",
    "print(f\"Dataset loaded:\")\n",
    "print(f\"  Videos: {len(metadata)}\")\n",
    "print(f\"  Similarity pairs: {len(pairs)}\")\n",
    "print(f\"  Unique labels: {metadata['label'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loader Setup\n",
    "\n",
    "Now let's create data loaders for training and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split pairs into train/val\n",
    "train_pairs, val_pairs = train_test_split(\n",
    "    pairs, test_size=0.2, random_state=42, stratify=pairs['similarity']\n",
    ")\n",
    "\n",
    "print(f\"Data split:\")\n",
    "print(f\"  Training pairs: {len(train_pairs)}\")\n",
    "print(f\"  Validation pairs: {len(val_pairs)}\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = VideoDataset(\n",
    "    pairs=train_pairs,\n",
    "    video_dir=data_dir,\n",
    "    max_frames=config['data']['max_frames'],\n",
    "    image_size=config['data']['image_size'],\n",
    "    is_training=True\n",
    ")\n",
    "\n",
    "val_dataset = VideoDataset(\n",
    "    pairs=val_pairs,\n",
    "    video_dir=data_dir,\n",
    "    max_frames=config['data']['max_frames'],\n",
    "    image_size=config['data']['image_size'],\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "print(f\"Datasets created:\")\n",
    "print(f\"  Training dataset: {len(train_dataset)} samples\")\n",
    "print(f\"  Validation dataset: {len(val_dataset)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['training']['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['training']['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['training']['num_workers'],\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created:\")\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 1: Data Loader Analysis\n",
    "\n",
    "**Task**: Analyze and optimize the data loading pipeline.\n",
    "\n",
    "**Requirements**:\n",
    "1. Calculate the memory usage of a single batch\n",
    "2. Measure data loading time for different batch sizes\n",
    "3. Implement data prefetching for faster loading\n",
    "4. Create a data loading benchmark\n",
    "5. Suggest optimizations for the data pipeline\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your data loader analysis code\n",
    "\n",
    "# 1. Calculate memory usage\n",
    "# Your code here...\n",
    "\n",
    "# 2. Measure loading time\n",
    "# Your code here...\n",
    "\n",
    "# 3. Implement prefetching\n",
    "# Your code here...\n",
    "\n",
    "# 4. Create benchmark\n",
    "# Your code here...\n",
    "\n",
    "# 5. Suggest optimizations\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model and Loss Function Setup\n",
    "\n",
    "Let's set up our model and loss functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "if config['model']['architecture'] == 'siamese':\n",
    "    model = VideoSiameseNetwork(\n",
    "        feature_dim=config['model']['feature_dim'],\n",
    "        embedding_dim=config['model']['embedding_dim']\n",
    "    )\n",
    "    loss_fn = ContrastiveLoss(margin=config['training']['margin'])\n",
    "elif config['model']['architecture'] == 'triplet':\n",
    "    model = VideoTripletNetwork(\n",
    "        feature_dim=config['model']['feature_dim'],\n",
    "        embedding_dim=config['model']['embedding_dim']\n",
    "    )\n",
    "    loss_fn = TripletLoss(margin=config['training']['margin'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown architecture: {config['model']['architecture']}\")\n",
    "\n",
    "print(f\"Model created: {config['model']['architecture']}\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Loss function: {type(loss_fn).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up optimizer\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=config['training']['learning_rate'],\n",
    "    weight_decay=config['training']['weight_decay']\n",
    ")\n",
    "\n",
    "# Set up learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(\n",
    "    optimizer,\n",
    "    step_size=config['training']['lr_step_size'],\n",
    "    gamma=config['training']['lr_gamma']\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: {type(optimizer).__name__}\")\n",
    "print(f\"Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"Weight decay: {config['training']['weight_decay']}\")\n",
    "print(f\"Scheduler: {type(scheduler).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 2: Optimizer and Scheduler Analysis\n",
    "\n",
    "**Task**: Analyze and compare different optimizers and schedulers.\n",
    "\n",
    "**Requirements**:\n",
    "1. Implement different optimizers (SGD, AdamW, RMSprop)\n",
    "2. Create different learning rate schedulers (cosine, exponential, plateau)\n",
    "3. Compare optimizer convergence on a simple loss function\n",
    "4. Analyze the impact of different learning rates\n",
    "5. Suggest optimal optimizer/scheduler combinations\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your optimizer and scheduler analysis code\n",
    "\n",
    "# 1. Implement different optimizers\n",
    "# Your code here...\n",
    "\n",
    "# 2. Create different schedulers\n",
    "# Your code here...\n",
    "\n",
    "# 3. Compare convergence\n",
    "# Your code here...\n",
    "\n",
    "# 4. Analyze learning rate impact\n",
    "# Your code here...\n",
    "\n",
    "# 5. Suggest optimal combinations\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Loop Setup\n",
    "\n",
    "Let's create the training loop with validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        video1, video2, labels = batch\n",
    "        video1, video2 = video1.to(device), video2.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if isinstance(model, VideoSiameseNetwork):\n",
    "            predictions = model(video1, video2)\n",
    "            loss = loss_fn(predictions, labels.float())\n",
    "        else:\n",
    "            # For triplet networks, we need to handle differently\n",
    "            # This is a simplified version\n",
    "            anchor, positive, negative = video1, video2, video1  # Simplified\n",
    "            anchor_emb, pos_emb, neg_emb = model(anchor, positive, negative)\n",
    "            loss = loss_fn(anchor_emb, pos_emb, neg_emb)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "# Validation function\n",
    "def validate_epoch(model, val_loader, loss_fn, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(val_loader, desc=\"Validation\")\n",
    "        for batch in progress_bar:\n",
    "            video1, video2, labels = batch\n",
    "            video1, video2 = video1.to(device), video2.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            if isinstance(model, VideoSiameseNetwork):\n",
    "                predictions = model(video1, video2)\n",
    "                loss = loss_fn(predictions, labels.float())\n",
    "            else:\n",
    "                anchor, positive, negative = video1, video2, video1  # Simplified\n",
    "                anchor_emb, pos_emb, neg_emb = model(anchor, positive, negative)\n",
    "                loss = loss_fn(anchor_emb, pos_emb, neg_emb)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    return total_loss / num_batches\n",
    "\n",
    "print(\"Training and validation functions created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 3: Training Loop Optimization\n",
    "\n",
    "**Task**: Optimize the training loop for better performance.\n",
    "\n",
    "**Requirements**:\n",
    "1. Implement gradient clipping to prevent exploding gradients\n",
    "2. Add early stopping to prevent overfitting\n",
    "3. Implement model checkpointing\n",
    "4. Add training metrics tracking (accuracy, precision, recall)\n",
    "5. Create a training visualization dashboard\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your training loop optimization code\n",
    "\n",
    "# 1. Implement gradient clipping\n",
    "# Your code here...\n",
    "\n",
    "# 2. Add early stopping\n",
    "# Your code here...\n",
    "\n",
    "# 3. Implement checkpointing\n",
    "# Your code here...\n",
    "\n",
    "# 4. Add metrics tracking\n",
    "# Your code here...\n",
    "\n",
    "# 5. Create visualization dashboard\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Augmentation Setup\n",
    "\n",
    "Let's set up data augmentation strategies for better generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define augmentation transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data augmentation transforms created:\")\n",
    "print(\"Training transforms:\")\n",
    "for transform in train_transforms.transforms:\n",
    "    print(f\"  - {type(transform).__name__}\")\n",
    "print(\"\\nValidation transforms:\")\n",
    "for transform in val_transforms.transforms:\n",
    "    print(f\"  - {type(transform).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ EXERCISE 4: Data Augmentation Analysis\n",
    "\n",
    "**Task**: Analyze and design effective data augmentation strategies.\n",
    "\n",
    "**Requirements**:\n",
    "1. Implement video-specific augmentations (temporal cropping, frame dropping)\n",
    "2. Create a function to visualize augmented samples\n",
    "3. Compare the effectiveness of different augmentation strategies\n",
    "4. Implement adaptive augmentation based on training progress\n",
    "5. Suggest domain-specific augmentations for video similarity\n",
    "\n",
    "**Your code here**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your data augmentation analysis code\n",
    "\n",
    "# 1. Implement video-specific augmentations\n",
    "# Your code here...\n",
    "\n",
    "# 2. Create visualization function\n",
    "# Your code here...\n",
    "\n",
    "# 3. Compare augmentation strategies\n",
    "# Your code here...\n",
    "\n",
    "# 4. Implement adaptive augmentation\n",
    "# Your code here...\n",
    "\n",
    "# 5. Suggest domain-specific augmentations\n",
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training Configuration Summary\n",
    "\n",
    "Let's summarize our training setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== TRAINING SETUP SUMMARY ===\")\n",
    "print(f\"\\nData Configuration:\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Batch size: {config['training']['batch_size']}\")\n",
    "print(f\"  Max frames per video: {config['data']['max_frames']}\")\n",
    "print(f\"  Image size: {config['data']['image_size']}\")\n",
    "\n",
    "print(f\"\\nModel Configuration:\")\n",
    "print(f\"  Architecture: {config['model']['architecture']}\")\n",
    "print(f\"  Feature dimension: {config['model']['feature_dim']}\")\n",
    "print(f\"  Embedding dimension: {config['model']['embedding_dim']}\")\n",
    "print(f\"  Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Optimizer: {type(optimizer).__name__}\")\n",
    "print(f\"  Learning rate: {config['training']['learning_rate']}\")\n",
    "print(f\"  Weight decay: {config['training']['weight_decay']}\")\n",
    "print(f\"  Loss function: {type(loss_fn).__name__}\")\n",
    "print(f\"  Margin: {config['training']['margin']}\")\n",
    "\n",
    "print(f\"\\nHardware Configuration:\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ FINAL EXERCISE: Training Setup Report\n",
    "\n",
    "**Task**: Write a comprehensive report on training setup optimization.\n",
    "\n",
    "**Requirements**:\n",
    "1. Analyze the current training setup and identify bottlenecks\n",
    "2. Suggest improvements for data loading efficiency\n",
    "3. Recommend optimal hyperparameters for different scenarios\n",
    "4. Propose a training monitoring and debugging strategy\n",
    "5. Design a scalable training pipeline for large datasets\n",
    "\n",
    "**Your report here** (write in markdown):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write your training setup report\n",
    "report = \"\"\"\n",
    "## Training Setup Report\n",
    "\n",
    "### Current Setup Analysis:\n",
    "[Your analysis here]\n",
    "\n",
    "### Data Loading Improvements:\n",
    "[Your suggestions here]\n",
    "\n",
    "### Optimal Hyperparameters:\n",
    "[Your recommendations here]\n",
    "\n",
    "### Monitoring Strategy:\n",
    "[Your proposal here]\n",
    "\n",
    "### Scalable Pipeline:\n",
    "[Your design here]\n",
    "\"\"\"\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've set up:\n",
    "\n",
    "âœ… **Data Preparation**: Created train/validation splits and data loaders\n",
    "âœ… **Model Setup**: Initialized models and loss functions\n",
    "âœ… **Optimizer Configuration**: Set up optimizers and learning rate schedulers\n",
    "âœ… **Training Loop**: Created training and validation functions\n",
    "âœ… **Data Augmentation**: Implemented augmentation strategies\n",
    "âœ… **4 Interactive Exercises**: Hands-on training setup optimization\n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "1. **Data Loading Efficiency**: Proper data loading setup is crucial for training speed\n",
    "2. **Optimizer Choice**: Different optimizers work better for different scenarios\n",
    "3. **Learning Rate Scheduling**: Proper LR scheduling can significantly improve convergence\n",
    "4. **Data Augmentation**: Augmentation helps prevent overfitting and improves generalization\n",
    "5. **Monitoring**: Proper training monitoring helps identify issues early\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "In the next notebook, we'll learn about **Model Training** - how to actually train our models and monitor their performance.\n",
    "\n",
    "---\n",
    "\n",
    "**Questions to think about:**\n",
    "- What would be the optimal batch size for your hardware?\n",
    "- How would you handle class imbalance in the training data?\n",
    "- What augmentation strategies would work best for your video domain?\n",
    "- How would you implement distributed training for large datasets?\n",
    "- What metrics would you track during training?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}